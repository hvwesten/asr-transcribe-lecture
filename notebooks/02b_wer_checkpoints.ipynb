{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b48a2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import jiwer\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e546032",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#model_dir = \"wav2vec2-base-960h\" # baseline\n",
    "#model_dir = \"wav2vec2-base\"\n",
    "#model_dir = \"wav2vec2-base-100h\"\n",
    "\n",
    "#model_dir = \"wav2vec2-large-960h\"\n",
    "model_dir = \"wav2vec2-large-robust-ft-libri-960h\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04df35b3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_directory = Path.cwd().parent\n",
    "\n",
    "dataset_name = \"yale_econ251\"\n",
    "data_dir = base_directory / 'data'\n",
    "\n",
    "dataset_size = \"normal\" # or 'tiny'\n",
    "\n",
    "if dataset_size == \"tiny\":\n",
    "    audio_dir = data_dir / 'inputs' / dataset_name / 'lectures-tiny'\n",
    "    transcripts_dir = data_dir / 'inputs' / dataset_name / 'transcripts-tiny'\n",
    "else:\n",
    "    audio_dir = data_dir / 'inputs' / dataset_name / 'lectures'\n",
    "    transcripts_dir = data_dir / 'inputs' / dataset_name / 'transcripts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b71fd24-0bdb-41b6-b3c7-c46a73a7e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dir = data_dir / 'predictions' / dataset_name / model_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d384f357",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transformation = jiwer.Compose([\n",
    "    jiwer.ToUpperCase(),\n",
    "    jiwer.RemoveWhiteSpace(replace_by_space=True),\n",
    "    jiwer.RemoveMultipleSpaces(),\n",
    "    jiwer.RemovePunctuation(),\n",
    "    jiwer.ReduceToListOfListOfWords(word_delimiter=\" \")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276513c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "\n",
    "# selected_files = ['01', '02', '03', '04', '05' ]\n",
    "chunk_length = \"_cl10\"\n",
    "\n",
    "for transcript in transcripts_dir.glob('*.txt'):\n",
    "    file_no = transcript.stem\n",
    "    # if file_no not in selected_files:\n",
    "    #     continue\n",
    "\n",
    "    # load the ground truth text\n",
    "    with open(transcript, 'r') as f:\n",
    "        ground_truth = f.read()\n",
    "\n",
    "    # load the predicted text\n",
    "    pred_file_name = 'pred__' + file_no + \"_\" + dataset_size\n",
    "    pred_file_path = (predictions_dir/ dataset_size / pred_file_name).with_suffix('.txt')\n",
    "    print(pred_file_path)\n",
    "    with open(pred_file_path, 'r') as f:\n",
    "        hypothesis = f.read()\n",
    "\n",
    "    measures = jiwer.compute_measures(ground_truth,\n",
    "                                      hypothesis,\n",
    "                                      truth_transform=transformation,\n",
    "                                      hypothesis_transform=transformation)\n",
    "    wer = measures['wer']\n",
    "    mer = measures['mer']\n",
    "    wil = measures['wil']\n",
    "\n",
    "    errors.append([wer, mer, wil])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a95ca9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xrange = [i for i in range(len(errors))]\n",
    "\n",
    "plt.plot(xrange, np.array(errors)[:,0], label=\"WER\")\n",
    "plt.plot(xrange, np.array(errors)[:,1], label=\"MER\")\n",
    "plt.plot(xrange, np.array(errors)[:,2], label=\"WIL\")\n",
    "plt.title(f\"{dataset_name}\")\n",
    "plt.xlabel(\"lecture no.\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average WER: {np.average(np.array(errors)[:,0])}\")\n",
    "print(f\"Average MER: {np.average(np.array(errors)[:,1])}\")\n",
    "print(f\"Average WIL: {np.average(np.array(errors)[:,2])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4190c8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compare chunk lengths\n",
    "\n",
    "ground_truth_file = transcripts_directory / \"01.txt\"\n",
    "with open(ground_truth_file, 'r') as f:\n",
    "    ground_truth = f.read()\n",
    "\n",
    "\n",
    "predicted_texts = [\"01_cl5.txt\", \"01_cl10.txt\", \"01_cl15.txt\", \"01_cl20.txt\"]\n",
    "errors = []\n",
    "#\n",
    "for pred in predicted_texts:\n",
    "    file_path = predictions_directory / pred\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        hypothesis = f.read()\n",
    "\n",
    "    error = jiwer.wer(\n",
    "        ground_truth,\n",
    "        hypothesis,\n",
    "        truth_transform=transformation,\n",
    "        hypothesis_transform=transformation\n",
    "    )\n",
    "\n",
    "    measures = jiwer.compute_measures(ground_truth,\n",
    "                                      hypothesis,\n",
    "                                      truth_transform=transformation,\n",
    "                                      hypothesis_transform=transformation)\n",
    "    wer = measures['wer']\n",
    "    mer = measures['mer']\n",
    "    wil = measures['wil']\n",
    "\n",
    "    errors.append([wer, mer, wil])\n",
    "    # errors.append(error)\n",
    "\n",
    "time_taken = [262, 268, 298, 377 ] # in seconds\n",
    "\n",
    "print(f\"WER: {np.array(errors)[:,0]}\")\n",
    "print(f\"MER: {np.array(errors)[:,1]}\")\n",
    "print(f\"WIL: {np.array(errors)[:,2]}\")\n",
    "\n",
    "print(time_taken)\n",
    "\n",
    "plt.plot(predicted_texts, errors)\n",
    "plt.title(f\"Compare chunk lengths for lecture 01\")\n",
    "plt.xlabel(\"Chunk length \")\n",
    "plt.ylabel(\"WER\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
