{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0ef1ffd-8eb3-4b60-8a72-5a4d78ee9cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
      "  Using cached https://github.com/kpu/kenlm/archive/master.zip\n",
      "Requirement already satisfied: pyctcdecode in /home/hvwesten/miniconda3/envs/asr/lib/python3.9/site-packages (0.3.0)\n",
      "Requirement already satisfied: pygtrie<3.0,>=2.1 in /home/hvwesten/miniconda3/envs/asr/lib/python3.9/site-packages (from pyctcdecode) (2.4.2)\n",
      "Requirement already satisfied: hypothesis<7,>=6.14 in /home/hvwesten/miniconda3/envs/asr/lib/python3.9/site-packages (from pyctcdecode) (6.46.6)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.15.0 in /home/hvwesten/miniconda3/envs/asr/lib/python3.9/site-packages (from pyctcdecode) (1.21.6)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/hvwesten/miniconda3/envs/asr/lib/python3.9/site-packages (from hypothesis<7,>=6.14->pyctcdecode) (21.4.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /home/hvwesten/miniconda3/envs/asr/lib/python3.9/site-packages (from hypothesis<7,>=6.14->pyctcdecode) (2.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install https://github.com/kpu/kenlm/archive/master.zip pyctcdecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9778287e-ce0b-41fe-8a9f-52f9081e9a7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jiwer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Optional, Union\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjiwer\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jiwer'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Union\n",
    "import jiwer\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset, Audio\n",
    "from datasets import load_metric\n",
    "# from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Processor, Wav2Vec2CTCTokenizer\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from transformers import Wav2Vec2ProcessorWithLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "634c006f-89bb-45f4-916b-6f5176b1043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = Path.cwd().parent\n",
    "\n",
    "dataset_name = \"yale/econ251\"\n",
    "data_dir = base_directory / 'data'\n",
    "# audio_dir = data_dir / 'inputs' / dataset_name / 'lectures'\n",
    "audio_dir = data_dir / 'inputs' / dataset_name / 'lectures-tiny'\n",
    "predictions_dir = data_dir / 'predictions' / dataset_name\n",
    "\n",
    "# transcripts_dir = data_dir / 'inputs' / dataset_name / 'transcripts'\n",
    "transcripts_dir = data_dir / 'inputs' / dataset_name / 'transcripts-tiny'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b0686d9-f3dc-404b-bffd-ca6d9ab2505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_files = [str(text_file) for text_file in transcripts_dir.glob('*.txt') if\n",
    "             'tiny' in str(text_file)]\n",
    "# txt_files = sorted(txt_files)[:7]\n",
    "\n",
    "mp3_files = [str(audio_file) for audio_file in audio_dir.glob('*.mp3') if\n",
    "             'tiny' in str(audio_file)]\n",
    "# mp3_files = sorted(mp3_files)[:7]\n",
    "\n",
    "data_dict = {\n",
    "    'mp3': mp3_files,\n",
    "    'txt': txt_files,\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data_dict, split=\"all\")\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "dataset = dataset.cast_column(\"mp3\", Audio(sampling_rate=16_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "769090ec-2be5-42e3-a356-a54ad6fd2c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0eed521772456da57e2b2daa9b9806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525b07f017bc4ff5aab1c36ae37d1a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' okay  but now i want to move to the next topic  w'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\"]'\n",
    "# chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\½\"]'\n",
    "\n",
    "# ignore_list = ['½', 'à', 'â', 'é', 'ï', '–', '—', '‘', '’', '“', '”', '…<', '=', '>',\n",
    "#                '$', '%', '&', '(', ')', '+', '/', '0', '1', '2', '3', '4', '5', '6',\n",
    "#                '7', '8', '9']\n",
    "# '%': 'percent',\n",
    "# '$': 'dollar',\n",
    "# '+': 'plus',\n",
    "# '-': 'minus',\n",
    "# '½': 'half',\n",
    "\n",
    "chars_to_ignore_regex = \"[\\,\\?\\.\\!\\-\\;\\:\\\"½+-0123456789&%$()=><…—–\\n]\"\n",
    "#\n",
    "replace_dict = {\n",
    "    'à': 'a',\n",
    "    'â': 'a',\n",
    "    'é': 'e',\n",
    "    'ï': 'i',\n",
    "    '”': '\"',\n",
    "    '“': '\"',\n",
    "    '‘': \"'\",\n",
    "    '’': \"'\",\n",
    "}\n",
    "\n",
    "\n",
    "def retrieve_text(batch):\n",
    "    # load the contents of the file as a string\n",
    "    txt_file = batch[\"txt\"]\n",
    "    with open(txt_file, 'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    for k, v in replace_dict.items():\n",
    "        text = text.replace(k, v)\n",
    "\n",
    "    # text = re.sub('[\\n]', ' ', text)\n",
    "\n",
    "    # text = re.sub(chars_to_replace_1, '\"', text)\n",
    "\n",
    "    # do some processing\n",
    "    batch[\"txt\"] = re.sub(chars_to_ignore_regex, ' ', text).lower()\n",
    "    return batch\n",
    "\n",
    "\n",
    "dataset = dataset.map(retrieve_text)\n",
    "\n",
    "dataset[\"train\"][0][\"txt\"][:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74cdc103-e226-4fb7-ac14-4885a2544cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['mp3', 'txt'],\n",
       "        num_rows: 20\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['mp3', 'txt'],\n",
       "        num_rows: 6\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "330ba4df-4f39-401e-be76-e08042ba6820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" so we're talking now about mortgages and how to value them  and if you remember now a mortgage so the first mortgages  by the way  that we know of  come from babylonian times  it's not like some american invented the mortgage or something   this was             years old and we have on these cuneiform tablets these mortgages  and so the idea of a mortgage is you make a promise  you back your promise with collateral  so if you don't keep the promise they can take your house  and there's some way of getting out of the promise because everybody knows the collateral  you might want to leave the home  and then you have to have some way of dissolving the promise because the promise involves many payments over time   so it's making a promise  backing it with collateral  and finding a way to dissolve the promise at prearranged terms in case you want to end it by prepaying  and that prepaying is called the refinancing option  and because there's a refinancing option it makes the mortgage a much more complicated thing  and a much more interesting thing  and something that  for example  a hedge fund could imagine that it could make money trading  so i just want to give you a slight indication of how that could happen   so as we said if you have a typical mortgage  say the mortgage rate is   percent maybe this is a different answer than i did so here we have an   percent mortgage with a   percent interest rate to begin with  \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_sample = dataset[\"train\"][2]\n",
    "audio_sample[\"txt\"].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7694962e-2f28-4ad8-967f-a8d781992585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-100h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.mask_time_emb_vector']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-100h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-100h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-100h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac00680f-a793-45b1-be2b-a294276d6933",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(audio_sample[\"mp3\"][\"array\"], sampling_rate=audio_sample[\"mp3\"][\"sampling_rate\"], return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c5cc57-f082-4f36-8959-c9d80a9869a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3e43d3-ec38-4eda-846f-b78c3bb06e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.batch_decode(predicted_ids)\n",
    "\n",
    "no_lm = transcription[0].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be8bb77-ef81-43fd-968e-d1333b108b83",
   "metadata": {},
   "source": [
    "## NGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15608b32-f432-44bd-a8df-d2d38f051251",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Wav2Vec2ProcessorWithLM.from_pretrained(\"patrickvonplaten/wav2vec2-base-100h-with-lm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8efdda0d-b636-4b8e-802a-2090e24adf81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"' </s> <pad> <s> <unk> A B C D E F G H I J K L M N O P Q R S T U V W X Y Z |\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(sorted(processor.tokenizer.get_vocab()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "749f6948-d7df-49b1-b3ba-a5729a52e8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = processor.batch_decode(logits.numpy()).text\n",
    "with_lm = transcription[0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4c8f265-8a9d-42e1-bf6d-4f8a4612bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = \"\"\"Time to start. So this class and the next class and a half are going to be about Fisher’s theory of present value and the interest rate, and then we’re going to move to uncertainty.\n",
    "\n",
    "So up until now what we’ve done is we found out first, if you know the whole economic system, how to solve for equilibrium. To figure out from the primitives of people’s tastes, their impatience, the technology, the economy, how to figure out the real rate of interest if provided there is no uncertainty in the world and people can forecast what is going to happen later.\n",
    "\n",
    "We’ve found that once you’ve done that, the price of every asset, if people are rational and looking forward to the future, the price of every asset is going to be the present value of the future payments of the asset. So if you think of the payments as real payments, which is what Fisher always recommended, you discount by the real interest rate. If you think of them as cash payments then you discount by the nominal interest rate. So every asset corresponds to its present value of its dividends either discounted by the real rate or the nominal rate.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76476a3c-57a9-41ea-8ead-87697e62aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = jiwer.Compose([\n",
    "    jiwer.ToUpperCase(),\n",
    "    jiwer.RemoveWhiteSpace(replace_by_space=True),\n",
    "    jiwer.RemoveMultipleSpaces(),\n",
    "    jiwer.RemovePunctuation(),\n",
    "    jiwer.ReduceToListOfListOfWords(word_delimiter=\" \")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b61fc3e-9050-4e27-9461-5d7018a8f30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wer': 1.3349753694581281, 'mer': 0.9033333333333333, 'wil': 0.9861904761904762, 'wip': 0.013809523809523808, 'hits': 29, 'substitutions': 174, 'deletions': 0, 'insertions': 97}\n"
     ]
    }
   ],
   "source": [
    "print(jiwer.compute_measures(gt,\n",
    "                             no_lm,\n",
    "                             truth_transform=transformation,\n",
    "                             hypothesis_transform=transformation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acd9c6a8-8c57-4b75-85e5-bcc44c7edb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wer': 1.29064039408867, 'mer': 0.903448275862069, 'wil': 0.9866825208085612, 'wip': 0.013317479191438763, 'hits': 28, 'substitutions': 175, 'deletions': 0, 'insertions': 87}\n"
     ]
    }
   ],
   "source": [
    "print(jiwer.compute_measures(gt,\n",
    "                             with_lm,\n",
    "                             truth_transform=transformation,\n",
    "                             hypothesis_transform=transformation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde5e589-d199-41d0-acdd-a40c01722617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
