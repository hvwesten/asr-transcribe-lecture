{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Speech recognition using DeepSpeech"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "audio_directory = Path.cwd() / 'audio'\n",
    "raw_text_directory = Path.cwd() / 'raw_text'\n",
    "normal_text_directory = Path.cwd() / 'normal_text'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# deepspeech --model deepspeech-0.9.3-models.pbmm --scorer deepspeech-0.9.3-models.scorer --audio audio/2830-3980-0043.wav\n",
    "# also\n",
    "# beam_width # Beam width for the CTC decoder\n",
    "# lm_alpha # Language model weight (lm_alpha). If not specified, use default from the scorer package.\n",
    "# lm_beta # Word insertion bonus (lm_beta). If not specified, use default from the scorer package.\n",
    "# parser.add_argument('--version', action=VersionAction,\n",
    "#                     help='Print version and exits')\n",
    "# parser.add_argument('--extended', required=False, action='store_true',\n",
    "#                     help='Output string from extended metadata')\n",
    "# parser.add_argument('--json', required=False, action='store_true',\n",
    "#                     help='Output json from metadata with timestamp of each word')\n",
    "# parser.add_argument('--candidate_transcripts', type=int, default=3,\n",
    "#                     help='Number of candidate transcripts to include in JSON output')\n",
    "# parser.add_argument('--hot_words', type=str,\n",
    "#                     help='Hot-words and their boosts.')\n",
    "\n",
    "\n",
    "# Inference took 1259.075s for 4456.333s audio file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "id": "118fc752-a909-44c4-8d6d-117689803aae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "\n",
    "print(f\"Loading model from file {model_file}\")\n",
    "model_load_start = timer()\n",
    "\n",
    "# Creating a model instance and loading model\n",
    "ds = Model(model_file)\n",
    "\n",
    "model_load_end = timer() - model_load_start\n",
    "print('Loaded model in {:.3}s.'.format(model_load_end), file=sys.stderr)\n",
    "\n",
    "# if args.beam_width:\n",
    "    # ds.setBeamWidth(args.beam_width)\n",
    "\n",
    "desired_sample_rate = ds.sampleRate()\n",
    "\n",
    "if scorer_file:\n",
    "    print(f\"Loading scorer from files {scorer_file}\")\n",
    "    scorer_load_start = timer()\n",
    "    ds.enableExternalScorer(scorer_file)\n",
    "    scorer_load_end = timer() - scorer_load_start\n",
    "    print(f\"Loaded scorer in {scorer_load_end:.3}s.\")\n",
    "\n",
    "    # if args.lm_alpha and args.lm_beta:\n",
    "    #     ds.setScorerAlphaBeta(args.lm_alpha, args.lm_beta)\n",
    "\n",
    "# if args.hot_words:\n",
    "#     print('Adding hot-words', file=sys.stderr)\n",
    "#     for word_boost in args.hot_words.split(','):\n",
    "#         word,boost = word_boost.split(':')\n",
    "#         ds.addHotWord(word,float(boost))\n",
    "\n",
    "fin = wave.open(audio_file, 'rb')\n",
    "fs_orig = fin.getframerate()\n",
    "if fs_orig != desired_sample_rate:\n",
    "    print(f\"Warning: original sample rate ({fs_orig}) is different than {desired_sample_rate}hz. Resampling might produce erratic speech recognition.\")\n",
    "    fs_new, audio = convert_samplerate(audio_file, desired_sample_rate)\n",
    "else:\n",
    "    audio = np.frombuffer(fin.readframes(fin.getnframes()), np.int16)\n",
    "\n",
    "audio_length = fin.getnframes() * (1/fs_orig)\n",
    "fin.close()\n",
    "\n",
    "\n",
    "\n",
    "# Performing inference\n",
    "print(\"Running inference.\")\n",
    "inference_start = timer()\n",
    "if True:\n",
    "    print(metadata_to_string(ds.sttWithMetadata(audio, 1).transcripts[0]))\n",
    "elif args.json:\n",
    "    print(metadata_json_output(ds.sttWithMetadata(audio, args.candidate_transcripts)))\n",
    "else:\n",
    "    print(ds.stt(audio))\n",
    "inference_end = timer() - inference_start\n",
    "print(f\"Inference took {inference_end:0.3f}s for {audio_length:0.3f}s audio file.\")"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}